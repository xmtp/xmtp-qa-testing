name: TS_Delivery
description: "should verify message loss when receiving via 200 streams"

on:
  schedule:
    - cron: "*/40 * * * *" # every 40 min
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest
    environment: Dev
    env:
      DATADOG_API_KEY: ${{ secrets.DATADOG_API_KEY }}
      LOGGING_LEVEL: ${{ vars.LOGGING_LEVEL }}
      XMTP_ENV: ${{ vars.XMTP_ENV }}
      GEOLOCATION: ${{ vars.GEOLOCATION }}
      DELIVERY_AMOUNT: ${{ vars.DELIVERY_AMOUNT }}
      DELIVERY_RECEIVERS: ${{ vars.DELIVERY_RECEIVERS }}
      # Add environment variable to prevent SQLCipher mlock errors
      SQLCIPHER_NO_MLOCK: 1
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version-file: ".node-version"
          cache: "yarn"
        env:
          SKIP_YARN_COREPACK_CHECK: "1"
      # Configure system limits for SQLCipher memory locking
      - name: Configure system resources
        run: |
          echo "Setting resource limits for memory locking"
          # Increase max_map_count even higher
          sudo sysctl -w vm.max_map_count=524288

          # Set higher limits in both limits.conf and limit.d
          sudo bash -c 'echo "* soft memlock unlimited" >> /etc/security/limits.conf'
          sudo bash -c 'echo "* hard memlock unlimited" >> /etc/security/limits.conf'

          # Create a dedicated config file for our process
          sudo bash -c 'echo "* soft memlock unlimited" > /etc/security/limits.d/99-memlock.conf'
          sudo bash -c 'echo "* hard memlock unlimited" >> /etc/security/limits.d/99-memlock.conf'

          # Set higher max locked memory for this session
          ulimit -l unlimited || echo "ulimit command failed but continuing"

          # Apply limits immediately for the current session
          sudo prlimit --pid $ --memlock=unlimited:unlimited || echo "prlimit command failed but continuing"

          # Increase shared memory limits as well
          sudo sysctl -w kernel.shmmax=17179869184
          sudo sysctl -w kernel.shmall=4194304

          # Print current limits for debugging
          echo "Current memlock limits:"
          ulimit -a | grep "max locked memory"
          cat /proc/self/limits | grep "Max locked memory"
      - name: Ensure data folder exists
        run: mkdir -p .data
      - name: List data folder contents before caching
        run: ls -la .data
      - name: Cache data folder and .env file
        uses: actions/cache@v3
        with:
          path: |
            .data
            .env
          key: ${{ runner.os }}-TS_Delivery-cache
          restore-keys: |
            ${{ runner.os }}-TS_Delivery-
          enableCrossOsArchive: false
          fail-on-cache-miss: false
      - name: List data folder contents after cache restore
        run: ls -la .data
      - run: corepack enable
      - run: yarn
      - name: Run tests with retry
        run: |
          for i in {1..3}; do
            echo "Attempt $i..."
            # Run the test and filter out both HPKE errors and SQLCipher mlock errors
            yarn test TS_Delivery 2>&1 | grep -v "sqlcipher_mem_lock: mlock.*returned -1 errno=12" | grep -v "Hpke error: Key not found" | tee test_output.log
            
            # Check if the test passed (look for passing test indicators)
            if grep -q "PASS" test_output.log; then
              echo "Test passed successfully, ignoring HPKE and mlock errors"
              break
            fi
            
            if [ $i -eq 3 ]; then
              echo "Test failed after 3 attempts."
              exit 1
            fi
            sleep 10
          done
  # Call the reusable Datadog reporting workflow
  report-to-datadog:
    needs: test
    if: always()
    runs-on: ubuntu-latest
    environment: Dev
    steps:
      - name: Debug secret availability
        run: |
          if [ -n "${{ secrets.DATADOG_API_KEY }}" ]; then
            echo "Datadog API key is available (value hidden)"
          else
            echo "ERROR: Datadog API key is NOT available"
          fi

      - name: Send workflow status to Datadog
        run: |
          STATUS="${{ needs.test.result }}"
          WORKFLOW="${{ github.workflow }}"
          ENV="Dev"
          API_KEY="${{ secrets.DATADOG_API_KEY }}"

          # Debug API key presence (without revealing it)
          if [ -z "$API_KEY" ]; then
            echo "WARNING: Datadog API key is empty"
          else
            echo "Datadog API key is available (value hidden)"
          fi

          ALERT_TYPE="info"

          if [ "$STATUS" == "success" ]; then
            ALERT_TYPE="success"
            TITLE="GitHub Workflow $WORKFLOW Succeeded"
            TEXT="GitHub workflow $WORKFLOW completed successfully in $ENV environment"
          else
            ALERT_TYPE="error"
            TITLE="GitHub Workflow $WORKFLOW Failed"
            TEXT="GitHub workflow $WORKFLOW failed in $ENV environment"
          fi

          # Send event
          curl -X POST "https://api.datadoghq.com/api/v1/events" \
          -H "Content-Type: application/json" \
          -H "DD-API-KEY: $API_KEY" \
          -d @- << EOF
          {
            "title": "$TITLE",
            "text": "$TEXT\n\nRepository: $GITHUB_REPOSITORY\nBranch: $GITHUB_REF_NAME\nRun ID: $GITHUB_RUN_ID\nTriggered by: $GITHUB_ACTOR\nWorkflow URL: https://github.com/$GITHUB_REPOSITORY/actions/runs/$GITHUB_RUN_ID",
            "alert_type": "$ALERT_TYPE",
            "source_type_name": "github",
            "tags": [
              "workflow:$WORKFLOW",
              "environment:$ENV",
              "repository:$GITHUB_REPOSITORY",
              "branch:$GITHUB_REF_NAME", 
              "run_id:$GITHUB_RUN_ID",
              "status:$STATUS",
              "triggered_by:$GITHUB_ACTOR"
            ]
          }
          EOF

          # Send metric for monitoring
          METRIC_VALUE=$([ "$STATUS" == "success" ] && echo "1" || echo "0")

          curl -X POST "https://api.datadoghq.com/api/v1/series" \
          -H "Content-Type: application/json" \
          -H "DD-API-KEY: $API_KEY" \
          -d @- << EOF
          {
            "series": [
              {
                "metric": "github.workflow.status",
                "type": "gauge",
                "points": [[$(date +%s), $METRIC_VALUE]],
                "tags": [
                  "workflow:$WORKFLOW",
                  "environment:$ENV",
                  "repository:$GITHUB_REPOSITORY",
                  "branch:$GITHUB_REF_NAME",
                  "triggered_by:$GITHUB_ACTOR"
                ]
              }
            ]
          }
          EOF
